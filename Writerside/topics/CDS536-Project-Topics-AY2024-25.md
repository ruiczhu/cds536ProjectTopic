# CDS536 Project Topics (AY2024-25)
---

## Project list:

1. **Power System Oscillations Localization**  
   Supervisor: Prof. Yanfang MO  
   Remarks: - [For Details](#topic-1-power-system-oscillations-localization)

2. **Satellite Pattern-of-Life Characterization**  
   Supervisor: Prof. Yanfang MO  
   Remarks: - [For Details](#topic-2-satellite-pattern-of-life-characterization)

3. **Advancing Gait Anomaly Detection through Multisensory Data Analysis**   
   Supervisor: Prof. Lisha YU  
   Remarks: - [For Details](#topic-3-advancing-gait-anomaly-detection-through-multisensory-data-analysis)

4. **Transforming Human-Computer Dialogues with Personality Annotation**  
   Supervisor: Prof. Jiaxing Shen  
   Remarks: - [For Details](#topic-4-transforming-human-computer-dialogues-with-personality-annotation)

5. **Dynamic Personality Recognition through Multimodal AI Systems**   
   Supervisor: Prof. Jiaxing Shen  
   Remarks: - [For Details](#topic-5-dynamic-personality-recognition-through-multimodal-ai-systems)

6. **Enabling Consistent Multi-Trait Personality Induction in LLMs**   
   Supervisor: Prof. Jiaxing Shen  
   Remarks: - [For Details](#topic-6-enabling-consistent-multi-trait-personality-induction-in-llms)

7. **Leveraging Generative AI for Enhanced Programming Guidance: A Student-Centric Approach**   
   Supervisor: Prof. FONG Chi Kit Ken  
   Remarks: - [For Details](#topic-7-leveraging-generative-ai-for-enhanced-programming-guidance-a-student-centric-approach)

8. **Innovative Tools for Evaluating Presentation Performance: A Computer Vision and Speech Approach**  
   Supervisor: Prof. FONG Chi Kit Ken  
   Remarks: - [For Details](#topic-8-innovative-tools-for-evaluating-presentation-performance-a-computer-vision-and-speech-approach)

9. **A mobile app promoting mindfulness and mental health**  
   Supervisor: Prof. LEE Kwan Yeung  
   Remarks: - [For Details](#topic-9-a-mobile-app-promoting-mindfulness-and-mental-health)

10. **A web application assisting university students in course selection**  
    Supervisor: Prof. LEE Kwan Yeung  
    Remarks: - [For Details](#topic-10-a-web-application-assisting-university-students-in-course-selection)

11. **A sign language interpreter software promoting equal opportunities**  
    Supervisor: Prof. LEE Kwan Yeung  
    Remarks: - [For Details](#topic-11-a-sign-language-interpreter-software-promoting-equal-opportunities)

12. **Automatic diagnosis of the atrial fibrillation with deep learning model**  
    Supervisor: Prof. LEE Kwan Yeung  
    Remarks: - [For Details](#topic-12-automatic-diagnosis-of-the-atrial-fibrillation-with-deep-learning-model)

13. **Developing a Policy QA System Using Retrieval-Augmented Generation (RAG) Framework**  
    Supervisor: Prof. Nan LI Nancy  
    Remarks: - [For Details](#topic-13-developing-a-policy-qa-system-using-retrieval-augmented-generation-rag-framework)

---

## Detailed Topics:

## Topic 1: Power System Oscillations Localization
**Supervisor:** Prof. Yanfang MO

**Description:**  
- Sustained oscillations in power systems can lead to equipment damage and system failures. With the massive deployment of phasor measurement units (PMUs), researchers have been exploring effective methods to characterize oscillations and identify their sources using PMU measurements.

**Reference:**
1. Osipov, Denis, Stavros Konstantinopoulos, and Joe H. Chow. "A cross-power spectral density method for locating oscillation sources using synchrophasor measurements." IEEE Transactions on Power Systems 38.6 (2022): 5526-5534.
2. Feng, Shuang, et al. "A two-stage deep transfer learning for localisation of forced oscillations disturbance source." International Journal of Electrical Power & Energy Systems 135 (2022): 107577.
3. Abdennadher, Yasmine. Localization of Forced Oscillation-A Model Based Approach. Diss. 2023.

**Remarks:**  
A strong interest in time series analysis and dynamic systems, along with competent programming skills, is preferred.

---

## Topic 2: Satellite Pattern-of-Life Characterization
**Supervisor:** Prof. Yanfang MO

**Description:**  
- As more satellites are launched, the space environment grows more congested. It is essential to protect space assets by improving tracking and orbit prediction capabilities. Consequently, researchers are motivated to analyze and characterize the satellites’ patterns of life (POL) —the behavioral narrative of a satellite in orbit—using the data collected from space.

**Reference:**
1. [Siew, Peng Mun, et al. "AI SSA Challenge Problem: Satellite Pattern-of-Life Characterization Dataset and Benchmark Suite." Proceedings of the 24th Advanced Maui Optical and Space Surveillance Technologies Conference (AMOS). 2023.](https://amostech.com/TechnicalPapers/2023/Machine-Learning-for-SDA/Siew2.pdf)
2. [Siew, Peng Mun, et al. "Satellite Pattern-of-Life Identification Challenge: Competition Design and Results."](https://amostech.com/TechnicalPapers/2024/Poster/Siew.pdf)

**Remarks:**  
A strong interest in time series analysis and dynamic systems, along with competent programming skills, is preferred.

---

## Topic 3: Advancing Gait Anomaly Detection through Multisensory Data Analysis
**Supervisor:** Prof. Lisha YU

**Type of Project:** Application

**Description:**  
- Gait anomaly detection plays a pivotal role in healthcare and research, offering crucial insights into health conditions by analyzing human movement patterns. Current methodologies often fall short in capturing the dynamic nuances within gait data, limiting accurate anomaly identification. By harnessing a variety of sensor data and exploring a spectrum of analytical approaches, this project aims to push the boundaries of anomaly detection systems. This comprehensive approach seeks to improve the precision and effectiveness of anomaly detection, paving the way for enhanced patient care and transformative healthcare practices.

**Reference:**
1. [Wang, X., Yu, L., Wang, H., Tsui, K. L., & Zhao, Y. (2024). Sensor-Based Multifaceted Feature Extraction and Ensemble Elastic Net Approach for Assessing Fall Risk in Community-Dwelling Older Adults. IEEE Journal of Biomedical and Health Informatics.](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10643648)
2. [Nguyen, T. N., Huynh, H. H., & Meunier, J. (2016). Skeleton-based abnormal gait detection. Sensors, 16(11), 1792.](https://www.mdpi.com/1424-8220/16/11/1792)
3. [Faisal, A. I., Mondal, T., & Deen, M. J. (2023). Systematic development of a simple human gait index. IEEE reviews in biomedical engineering, 17, 229-242.](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10132593)
4. [Jeon, S., Lee, K. M., & Koo, S. (2021). Anomalous gait feature classification from 3-D motion capture data. IEEE Journal of Biomedical and Health Informatics, 26(2), 696-703.](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9506854)

**Remarks:**  
Strong programming skills (R or Python) are assumed. Experience with sensor or high-dimensional data is appreciated.

---

## Topic 4: Transforming Human-Computer Dialogues with Personality Annotation
**Supervisor:** Prof. Jiaxing Shen

**Type of Project:** Research

**Description:**  
- The goal of this research is to create a large-scale dataset of Human-Computer Dialogue (HCD) annotated with detailed personality profiles. Current datasets often fail to distinguish between Human-Human Dialogue (HHD) and HCD, leading to a lack of nuanced data for training personality-aware AI systems. This project will address this gap by fine-tuning a large language model (LLM) to transform existing HCD datasets into dialogues that reflect specified personality traits while preserving semantic content. The method involves minimizing deviations in content while maximizing alignment with target personality traits using a dual-objective optimization approach.

- The first step is to explore psychological frameworks like the Big Five and MBTI to identify linguistic features that represent personality traits. These insights will guide the transformation of dialogues, ensuring alignment with target personalities. A comparative analysis of HHD and HCD will then be conducted to understand differences in communication patterns, relational engagement, and personality expression. Using these findings, an automated data enhancement pipeline will be developed to prepare high-quality training data for fine-tuning the LLM. Finally, the fine-tuned model will transform dialogues according to target personalities, evaluated through both human assessments and automated metrics for content fidelity and personality accuracy.

- This dataset will serve as a critical resource for advancing personality-aware AI systems, enabling more natural and empathetic interactions in domains such as education, healthcare, and customer service.

---

## Topic 5: Dynamic Personality Recognition through Multimodal AI Systems
**Supervisor:** Prof. Jiaxing Shen

**Type of Project:** Research

**Description:**  
- This research focuses on developing a system capable of dynamically recognizing and updating user personality traits during interactions using multimodal data. Traditional approaches rely on static or single-modality methods, limiting their ability to capture the evolving nature of human personalities. This project proposes a Bayesian framework that integrates conversation data (e.g., linguistic patterns) and interaction data (e.g., turn-taking behavior) to provide real-time personality estimates.

- The system begins with designing a user-friendly interface that collects multimodal data during interactions without requiring additional hardware, prioritizing conversational behavior over physical cues like facial expressions. The collected data is then processed using a Bayesian model that combines historical and real-time information to refine personality assessments continuously. Conversation data provides insights into linguistic styles, while interaction data captures behavioral patterns such as response times and engagement metrics. The Bayesian model updates its prior estimates with each new interaction round, ensuring that the AI adapts its responses based on evolving user profiles.

- This dynamic recognition capability enhances user engagement by making interactions feel more natural and personalized. The system's effectiveness will be validated through experiments measuring its ability to predict personality traits accurately across multiple interaction rounds.

---

## Topic 6: Enabling Consistent Multi-Trait Personality Induction in LLMs
**Supervisor:** Prof. Jiaxing Shen

**Type of Project:** Research

**Description:**  
- This research aims to enable large language models (LLMs) to emulate multiple personality traits consistently and accurately during interactions. Existing methods often focus on single traits or fail to resolve conflicts between multiple traits, leading to inconsistent or disjointed outputs. This project addresses these limitations by generating descriptive adjectives for various traits using domain knowledge (e.g., psychological frameworks) and refining them to eliminate potential conflicts using semantic knowledge graphs like ConceptNet.

- The first task involves generating a vocabulary of adjectives representing each trait based on psychological literature and augmenting it with synonyms from semantic graphs. Potential conflicts among adjectives are identified by analyzing antonyms and removing descriptors that could lead to contradictory outputs when inducing multiple traits simultaneously. These refined adjectives are used as prompts for LLMs to generate coherent summaries of specified personality profiles.

- The final step involves evaluating the model's ability to maintain consistent multi-trait personalities across diverse scenarios through both qualitative assessments and quantitative metrics such as coherence scores and user satisfaction ratings. This research will significantly enhance the richness of personality representation in conversational AI, improving trust and engagement in human-computer interactions.

---

## Topic 7: Leveraging Generative AI for Enhanced Programming Guidance: A Student-Centric Approach
**Supervisor:** Prof. FONG Chi Kit Ken

**Description:**  
- Programming is one of the essential skills for all Data Science students. Novice programmers often struggle to comprehend computer programming, as they must learn a variety of skills simultaneously, including programming constructs (such as lists, loops, conditional statements, etc.) and the debugging process. Many students dislike programming courses, believing that these subjects are difficult to learn. They frequently encounter issues in writing and designing clear programs. One significant factor contributing to this problem is the inadequate support provided to students. Additionally, there is a statistical correlation between learning styles and performance in computing-related courses. Artificial Intelligent (AI) interventions are needed to address this issue.

- Since 2022, Generative AI tools, such as ChatGPT, have become increasingly common across various sectors, including education at universities. However, their rapid growth and adoption raise integrity concerns, such as cheating and plagiarism. Throughout Kehinde Aruleba's studies, participants expressed concerns about students becoming overly reliant on these tools, which could lead to a decline in critical thinking and problem-solving skills. To enhance the teaching and learning of programming, it is essential to develop and adopt a ChatGPT-powered generative AI tool in programming classrooms.

- The objective of this project is to develop a tool that makes use of Generative AI to “comprehend students' coding attempts, detect any issues, and subsequently suggest improvements”. The tool is designed with the capability to interpret, execute, and evaluate the correctness of the coding attempt. If the attempt is not entirely accurate, the tool should identify the specific code snippet that requires enhancement and provides suggestions for improvement based on the attempted code.

**Reference:**  
Levy, Dan and Angela, Pérez Albertos. Teaching Effectively with ChatGPT: A practical guide to creating better learning experiences for your students in less time. Amazon, 2024.

---

## Topic 8: Innovative Tools for Evaluating Presentation Performance: A Computer Vision and Speech Approach
**Supervisor:** Prof. FONG Chi Kit Ken

**Description:**

- Effective communication is a critical skill in both academic and professional settings. Presentations are a common method for conveying ideas, sharing research, and persuading audiences. However, many individuals struggle with maintaining eye contact and delivering their messages clearly, which can significantly impact the effectiveness of their presentations.

- Recent advancements in computer vision and speech recognition technologies have opened new avenues for assessing and enhancing presentation skills. Computer vision techniques allow for real-time analysis of visual cues, such as eye contact, while speech recognition can transcribe spoken words into text, providing valuable insights into the clarity and content of the presentation.

- The motivation for this project stems from the need to provide presenters with actionable feedback that can help them improve their communication skills. Traditional methods of evaluation, such as peer reviews or self-assessment, can be subjective and may not accurately reflect a presenter’s performance. By integrating technology, this project aims to offer a more objective and comprehensive assessment.

- The objective of this project is to develop a comprehensive system that enhances presentation skills through the integration of computer vision and speech recognition technologies. Firstly, the project aims to create a robust eye contact detection mechanism that accurately tracks and quantifies eye contact during presentations, providing valuable metrics for performance evaluation. Secondly, it seeks to implement an efficient speech-to-text conversion system that transcribes spoken content with high accuracy. Additionally, the project will design a grading rubric to assess the presenter's performance based on key criteria, including the percentage of time spent maintaining eye contact, the clarity and coherence of the transcribed speech, and the overall quality of the presentation content.

**Reference:**
1. Chong, E., Clark-Whitney, E., Southerland, A., Stubbs, E., Miller, C., Ajodan, E. L., ... & Rehg, J. M. (2020). Detection of eye contact with deep neural networks is as accurate as human experts. Nature communications, 11(1), 6386.
2. MediaPipe Iris: Real-time Iris Tracking & Depth Estimation: [Google Research](https://research.google/blog/mediapipe-iris-real-time-iris-tracking-depth-estimation/)

---

## Topic 9: A mobile app promoting mindfulness and mental health
**Supervisor:** Prof. LEE Kwan Yeung

**Type of Project:** Application

**Description:**  
- Mindfulness refers to the basic skills that facilitate people's development of full awareness of where they are and what they are doing so that they will not be overly reactive or overwhelmed by what is happening around them. Mindfulness practices have been applied as therapies to address the problem of depression, stress, anxiety, and drug addiction. In this project, your team is required to develop a mobile app that promotes mental health by (1) guiding users to perform mindfulness practices interactively through a traditional step-by-step wizard complemented with a variety of multimedia and (2) recording the results of each mindfulness practice and regularly generating summary reports. Your team is also encouraged to explore the possibility of implementing a virtual mindfulness training tutor through customizing an existing large language model chatbot with prompt engineering.

---

## Topic 10: A web application assisting university students in course selection
**Supervisor:** Prof. LEE Kwan Yeung

**Type of Project:** Application

**Description:**  
- It is always difficult for first-year university students to get used to the paradigm shift from having every course preassigned to having the freedom to select courses they feel interested in. In this project, your team is required to develop a web application that assists students in selecting and scheduling courses. The web application is designed to (1) facilitate easier and more efficient course searching, (2) visualize every course that a student has selected with a timetable interface and (3) identify every potential time conflict between selected courses. Your team is also encouraged to explore the possibility of implementing a virtual academic advisor through customizing an existing large language model chatbot with prompt engineering.

---

## Topic 11: A sign language interpreter software promoting equal opportunities
**Supervisor:** Prof. LEE Kwan Yeung

**Type of Project:** Application

**Description:**  
- Sign language is the major way of communication for hearing-impaired people. However, sign language is not commonly taught as a second language in schools. As a result, it would often be challenging for hearing-impaired people to communicate with others in daily life. This communication barrier may be resolved if there is sophisticated software that can translate sign language into written language and vice versa. In this project, your team is required to develop software with a user-friendly GUI that can recognize sign language hand gestures in the live video feed captured from a camera and translate these gestures into written language. Your team is also encouraged to explore the possibility of translating written language into sign language hand gestures with generative AI models.

---

## Topic 12: Automatic diagnosis of the atrial fibrillation with deep learning model
**Supervisor:** Prof. LEE Kwan Yeung

**Type of Project:** Research

**Description:**  
- Atrial fibrillation (AF) refers to the medical condition that the atrial chambers of the heart are beating rapidly and irregularly which can increase the risk of stroke, heart failure, and other heart-related complications. Physicians can confirm their diagnosis of AF by interpreting the standard 12-lead ECG diagram. As a result, if a model can be learned to differentiate the ECG signals of healthy samples from the ECG signals of the AF patients, the diagnosis of AF can hence be automated. In this project, your team is expected to develop deep-learning models for detecting AF. Your team is also expected to conduct experiments to compare the performance of your model against existing models using public datasets.

**Reference:**  
Ribeiro, A.H., Ribeiro, M.H., Paixão, G.M.M. et al. Automatic diagnosis of the 12-lead ECG using a deep neural network. Nat Commun 11, 1760 (2020). [https://doi.org/10.1038/s41467-020-15432-4](https://doi.org/10.1038/s41467-020-15432-4)

---

## Topic 13: Developing a Policy QA System Using Retrieval-Augmented Generation (RAG) Framework
**Supervisor:** Prof. Nan LI Nancy

**Description:**  
- Policies are often complex, lengthy, and filled with technical language, making it challenging for individuals to extract the specific information they need efficiently. A policy QA System aims to bridge this gap by providing concise, accurate, and user-friendly answers to policy-related queries. Traditional QA systems typically have pre-defined QA pairs and then use information retrieval techniques to find QA pairs related to users’ questions. As LLM becomes popular, a machine can generate answers without retrieving information. However, generation-based systems often face a significant challenge – hallucinations, where the system generates incorrect or fabricated information that lacks grounding in factual data, which is a critical problem for a policy QA system.

- This project addresses the hallucination problem by developing a QA system based on the Retrieval-Augmented Generation (RAG) framework. RAG combines the best of retrieval-based and generation-based approaches, aiming to significantly reduce hallucinations in language model outputs by grounding answers in factual, retrieved data. The RAG framework operates through two main components: the retrieved part and the generation part. The retrieval part retrieves relevant policy documents or sections from policy documents on user queries. The generation part synthesizes an easy-to-understand response based on the retrieved content. Unlike standalone generative models that may invent fake details when faced with incomplete information, the RAG approach ensures that all answers are firmly rooted in the retrieved policy data. This enhances the credibility and reliability of the system. An additional challenge in building such a system is balancing speed and accuracy. While users often expect rapid responses, the system must also ensure that answers are precise and factually grounded. Students will explore various techniques to optimize this trade-off, ensuring that the QA system is both efficient and accurate for real-time policy inquiries.

**Techniques that may come across:**
- Strong programming skills.
- Familiar with NLP algorithms.

**Remarks:**
This is a practical-oriented project. Similar approaches have been adopted by several institutions. The depths of the knowledge used in the project will be tailored to students' capabilities. External staff support is available.

**Reference:**
1. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., ... & Kiela, D. (2020). Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33, 9459-9474.
2. Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., ... & Wang, H. (2023). Retrieval-augmented generation for large language models: A survey. arXiv preprint arXiv:2312.10997.